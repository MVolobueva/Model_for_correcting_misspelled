{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_for_correcting_misspelled.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9e65bf92e2d44d097fbd041695c52b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_940319d5cd0541c690abbdb0775e09e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc3733de53644f0782ac74a35dbf8995",
              "IPY_MODEL_eb83dedd448049aaa553dbd5b2d1251f"
            ]
          }
        },
        "940319d5cd0541c690abbdb0775e09e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc3733de53644f0782ac74a35dbf8995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_396d055e3ea944b693ef0c7f9be251d6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f65562ad941b483581d6fa9206410873"
          }
        },
        "eb83dedd448049aaa553dbd5b2d1251f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a1afc6c25e146518658c8f7e538e20b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 1.30kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b936d4ea9c87469ba22a7f2057554fbb"
          }
        },
        "396d055e3ea944b693ef0c7f9be251d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f65562ad941b483581d6fa9206410873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a1afc6c25e146518658c8f7e538e20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b936d4ea9c87469ba22a7f2057554fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "189a5c1c5d4b4fd4b82fec7faa5c3891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69c14ae485814f378a24f9571806e938",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5593c2d7fdb2416a99cf316465f389f7",
              "IPY_MODEL_f98830609ef242d2b78dfc1792124115"
            ]
          }
        },
        "69c14ae485814f378a24f9571806e938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5593c2d7fdb2416a99cf316465f389f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e4b7f42f4e5c404f91758c5a2ed84b5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc91df6905c34c54b16da8670b816725"
          }
        },
        "f98830609ef242d2b78dfc1792124115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f78b558c9bf4be68af5f998122ddd93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 693kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c801693d960842f8aacb280e2f0ff7b4"
          }
        },
        "e4b7f42f4e5c404f91758c5a2ed84b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc91df6905c34c54b16da8670b816725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f78b558c9bf4be68af5f998122ddd93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c801693d960842f8aacb280e2f0ff7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e7c337ea5d5445eaf38a87f66c50696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c25cc232afa74ae0bf15628cbb2425f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_994e4173574a4f039719d34526b4346a",
              "IPY_MODEL_53f791121916432ca0c248ea9b8f7339"
            ]
          }
        },
        "c25cc232afa74ae0bf15628cbb2425f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "994e4173574a4f039719d34526b4346a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35235e3318b24986947fe20645fe1e29",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3aa9cf3735841debbf094147c46adfd"
          }
        },
        "53f791121916432ca0c248ea9b8f7339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d0c47c80b1f04000af1ff3edf5a241cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 626kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10e6fdc379f34fadbd027416d6359d7e"
          }
        },
        "35235e3318b24986947fe20645fe1e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3aa9cf3735841debbf094147c46adfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0c47c80b1f04000af1ff3edf5a241cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10e6fdc379f34fadbd027416d6359d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64537d65908145999b317efba3d24771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff6e750735744c45930ddb87c8d62fb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_347d8fae1eb24ae8b04dbc5ac698b78e",
              "IPY_MODEL_71515af3281b4b8ca60632a579946884"
            ]
          }
        },
        "ff6e750735744c45930ddb87c8d62fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "347d8fae1eb24ae8b04dbc5ac698b78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6239781f9e0c405394c6c105f35ac358",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92073ff274954e12a51102b403b92f9a"
          }
        },
        "71515af3281b4b8ca60632a579946884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd8d427c5ac54d19a0aca93c0b19a545",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a7932d930a54b63b71ad4f1dbacfe46"
          }
        },
        "6239781f9e0c405394c6c105f35ac358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92073ff274954e12a51102b403b92f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd8d427c5ac54d19a0aca93c0b19a545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a7932d930a54b63b71ad4f1dbacfe46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ea9959fddfe49d7acb35394d1ffc8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2ca4b1a14bb4425b232e92674853f8d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f059d333cbaa42ab9cd97f0b29946366",
              "IPY_MODEL_bf24f94c053d4292baaaf8d7de4bb2ea"
            ]
          }
        },
        "e2ca4b1a14bb4425b232e92674853f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f059d333cbaa42ab9cd97f0b29946366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3447129adb2c42328c1a7daf8d83d0b6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_281cbc6d8f5146f9b0ccf7f214801a2b"
          }
        },
        "bf24f94c053d4292baaaf8d7de4bb2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7391e25da1ca4637849c14f42037e9f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:12&lt;00:00, 44.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bce1d63aec784c0abc6c884846b6c161"
          }
        },
        "3447129adb2c42328c1a7daf8d83d0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "281cbc6d8f5146f9b0ccf7f214801a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7391e25da1ca4637849c14f42037e9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bce1d63aec784c0abc6c884846b6c161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmwVdJg1LJnn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWFXbhAkLMh6"
      },
      "source": [
        "# Model for correcting misspellea words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR5cDVb-L5u1"
      },
      "source": [
        "This part of the notebook was taken from https://github.com/deepmipt/raai_summer_school_nlp_2021. In this part, you can find the demonstration of how to work with transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1YeHbFB4oZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd175ade-7022-4756-fd3f-05f24a319183"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 18.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 40kB 15.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 51kB 9.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 9.9MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |█                               | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |██                              | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |██                              | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 204kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 215kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 225kB 8.9MB/s eta 0:00:01\r\u001b[K     |███                             | 235kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 245kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 256kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 266kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 276kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 286kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 296kB 8.9MB/s eta 0:00:01\r\u001b[K     |████                            | 307kB 8.9MB/s eta 0:00:01\r\u001b[K     |████                            | 317kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 327kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 337kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 348kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 358kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 368kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 378kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 389kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 399kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 409kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 419kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 430kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 440kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 450kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 460kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 471kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 481kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 491kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 501kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 512kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 522kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 532kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 542kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 552kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 563kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 573kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 583kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 593kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 604kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 614kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 624kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 634kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 645kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 655kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 665kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 675kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 686kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 696kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 706kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 716kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 727kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 737kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 747kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 757kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 768kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 778kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 788kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 798kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 808kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 819kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 829kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 839kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 849kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 860kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 870kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 880kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 890kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 901kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 911kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 921kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 931kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 942kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 952kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 962kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 972kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 983kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 993kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.6MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.7MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.8MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.9MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 2.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 2.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.2MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.3MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.4MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.5MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 55.8MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sacremoses, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcUk4jtJ5Z2f"
      },
      "source": [
        "В современной компьютерной лингвистике вычисление вероятности текста производится в основном за счёт нейронных, а не энграммных моделей. Существует много разновидностей архитектур, мы рассмотрим 2: левостороннюю модель  `gpt2` (её облегчённую версию `distilgpt2`) и языковую модель с пропусками `BERT`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnUvo3gX6G6t"
      },
      "source": [
        "## Односторонние языковые модели\n",
        "\n",
        "Вначале создадим токенизатор и применим его к данным"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPIF2FkQ5ZZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "e9e65bf92e2d44d097fbd041695c52b6",
            "940319d5cd0541c690abbdb0775e09e8",
            "dc3733de53644f0782ac74a35dbf8995",
            "eb83dedd448049aaa553dbd5b2d1251f",
            "396d055e3ea944b693ef0c7f9be251d6",
            "f65562ad941b483581d6fa9206410873",
            "1a1afc6c25e146518658c8f7e538e20b",
            "b936d4ea9c87469ba22a7f2057554fbb",
            "189a5c1c5d4b4fd4b82fec7faa5c3891",
            "69c14ae485814f378a24f9571806e938",
            "5593c2d7fdb2416a99cf316465f389f7",
            "f98830609ef242d2b78dfc1792124115",
            "e4b7f42f4e5c404f91758c5a2ed84b5c",
            "cc91df6905c34c54b16da8670b816725",
            "5f78b558c9bf4be68af5f998122ddd93",
            "c801693d960842f8aacb280e2f0ff7b4",
            "2e7c337ea5d5445eaf38a87f66c50696",
            "c25cc232afa74ae0bf15628cbb2425f4",
            "994e4173574a4f039719d34526b4346a",
            "53f791121916432ca0c248ea9b8f7339",
            "35235e3318b24986947fe20645fe1e29",
            "d3aa9cf3735841debbf094147c46adfd",
            "d0c47c80b1f04000af1ff3edf5a241cd",
            "10e6fdc379f34fadbd027416d6359d7e",
            "64537d65908145999b317efba3d24771",
            "ff6e750735744c45930ddb87c8d62fb8",
            "347d8fae1eb24ae8b04dbc5ac698b78e",
            "71515af3281b4b8ca60632a579946884",
            "6239781f9e0c405394c6c105f35ac358",
            "92073ff274954e12a51102b403b92f9a",
            "bd8d427c5ac54d19a0aca93c0b19a545",
            "0a7932d930a54b63b71ad4f1dbacfe46"
          ]
        },
        "outputId": "0d342a3b-476b-46f6-ca47-e2e4d31127e0"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e65bf92e2d44d097fbd041695c52b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "189a5c1c5d4b4fd4b82fec7faa5c3891",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e7c337ea5d5445eaf38a87f66c50696",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64537d65908145999b317efba3d24771",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za_xJi6M6lur",
        "outputId": "64901a72-9f3c-41bf-ab19-eba8aac36cd5"
      },
      "source": [
        "text = \"The Starship prototype descended under active aerodynamic control, accomplished by four vehicles.\"\n",
        "tokenization = tokenizer(text)\n",
        "print(tokenization)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [464, 40172, 14879, 23667, 739, 4075, 9551, 34743, 1630, 11, 13013, 416, 1440, 5672, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW4OZNVq8Dya",
        "outputId": "d15d93a3-f98c-4e46-bf83-f9201c55851a"
      },
      "source": [
        "sents = [\n",
        "    \"Yesterday, all my troubles seemed so far away.\",\n",
        "    \"I only want to say, if there is a way, take away this cup of poison, 'cause it burns me.\",\n",
        "    \"We do not need your education, we do not need your thought control.\",\n",
        "    \"When the light begins to change, I sometimes feel a little strange, a little anxious when it's dark.\"         \n",
        "]\n",
        "for elem in tokenizer(sents)[\"input_ids\"]:\n",
        "    print(elem)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[28065, 11, 477, 616, 14979, 3947, 523, 1290, 1497, 13]\n",
            "[40, 691, 765, 284, 910, 11, 611, 612, 318, 257, 835, 11, 1011, 1497, 428, 6508, 286, 8764, 11, 705, 25587, 340, 20246, 502, 13]\n",
            "[1135, 466, 407, 761, 534, 3707, 11, 356, 466, 407, 761, 534, 1807, 1630, 13]\n",
            "[2215, 262, 1657, 6140, 284, 1487, 11, 314, 3360, 1254, 257, 1310, 6283, 11, 257, 1310, 18116, 618, 340, 338, 3223, 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cIRsdbT8WWk",
        "outputId": "c99e63f5-5d20-4097-ab91-fa2197650a84"
      },
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "for elem in tokenizer(sents, return_tensors=\"pt\", padding=True)[\"input_ids\"]:\n",
        "    print(elem)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([28065,    11,   477,   616, 14979,  3947,   523,  1290,  1497,    13,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256])\n",
            "tensor([   40,   691,   765,   284,   910,    11,   611,   612,   318,   257,\n",
            "          835,    11,  1011,  1497,   428,  6508,   286,  8764,    11,   705,\n",
            "        25587,   340, 20246,   502,    13])\n",
            "tensor([ 1135,   466,   407,   761,   534,  3707,    11,   356,   466,   407,\n",
            "          761,   534,  1807,  1630,    13, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256])\n",
            "tensor([ 2215,   262,  1657,  6140,   284,  1487,    11,   314,  3360,  1254,\n",
            "          257,  1310,  6283,    11,   257,  1310, 18116,   618,   340,   338,\n",
            "         3223,    13, 50256, 50256, 50256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhl-w1FP-78D"
      },
      "source": [
        " Загрузим модель на видеокарту."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "7ea9959fddfe49d7acb35394d1ffc8be",
            "e2ca4b1a14bb4425b232e92674853f8d",
            "f059d333cbaa42ab9cd97f0b29946366",
            "bf24f94c053d4292baaaf8d7de4bb2ea",
            "3447129adb2c42328c1a7daf8d83d0b6",
            "281cbc6d8f5146f9b0ccf7f214801a2b",
            "7391e25da1ca4637849c14f42037e9f7",
            "bce1d63aec784c0abc6c884846b6c161"
          ]
        },
        "id": "PfgzLWbn-_y1",
        "outputId": "c970d8a4-6afb-4987-ab26-4e8ba150fccb"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoModel\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"gpt2\").to(\"cuda\")\n",
        "type(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:847: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ea9959fddfe49d7acb35394d1ffc8be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVd-YCTYDEl_",
        "outputId": "94b79829-5310-4447-fd58-82755581b214"
      },
      "source": [
        "top_log_probs, top_indexes = torch.topk(logits[0], k=5, dim=-1)\n",
        "top_indexes = top_indexes.cpu().numpy()\n",
        "for i in range(len(logits[0])-1):\n",
        "    print(\"<BEGIN> \" + \" \".join([x.strip(\"ĠĊ\") for x in tokens[:i]]))\n",
        "    curr_top_tokens = tokenizer.convert_ids_to_tokens(top_indexes[i])\n",
        "    for index, token in zip(top_indexes[i], curr_top_tokens):\n",
        "        token = token.strip(\"ĠĊ\")\n",
        "        print(f\"{token}:{probs[i,index]:.3f}\", end=\" \")\n",
        "    print(\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BEGIN> \n",
            ":0.062 The:0.038 \":0.024 A:0.019 I:0.018 \n",
            "<BEGIN> The\n",
            "first:0.010 U:0.009 following:0.008 United:0.006 US:0.005 \n",
            "<BEGIN> The Starship\n",
            "Enterprise:0.213 Tro:0.212 Trooper:0.021 Ant:0.008 Crew:0.008 \n",
            "<BEGIN> The Starship prototype\n",
            "is:0.146 was:0.063 of:0.052 has:0.044 ,:0.042 \n",
            "<BEGIN> The Starship prototype descended\n",
            "into:0.391 to:0.135 from:0.115 on:0.041 in:0.019 \n",
            "<BEGIN> The Starship prototype descended under\n",
            "the:0.259 a:0.132 heavy:0.109 its:0.050 fire:0.041 \n",
            "<BEGIN> The Starship prototype descended under active\n",
            "investigation:0.103 fire:0.084 development:0.066 radar:0.043 construction:0.038 \n",
            "<BEGIN> The Starship prototype descended under active aer\n",
            "odynamic:0.790 odynamics:0.127 ob:0.036 on:0.022 opl:0.007 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic\n",
            "drag:0.327 control:0.104 braking:0.033 and:0.027 stress:0.025 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control\n",
            ",:0.127 and:0.073 during:0.066 on:0.064 at:0.062 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control ,\n",
            "and:0.114 but:0.085 which:0.041 with:0.041 the:0.032 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control , accomplished\n",
            "in:0.143 by:0.119 its:0.087 with:0.069 a:0.060 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control , accomplished by\n",
            "the:0.175 a:0.169 an:0.044 its:0.017 using:0.010 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control , accomplished by four\n",
            "engines:0.038 -:0.027 separate:0.018 different:0.017 small:0.015 \n",
            "<BEGIN> The Starship prototype descended under active aer odynamic control , accomplished by four vehicles\n",
            ".:0.148 ,:0.134 ::0.098 of:0.046 in:0.043 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mioXEbjKFpce"
      },
      "source": [
        "Теперь посмотрим, насколько модель знает грамматику."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JSUfaCa9eIW",
        "outputId": "4362cb34-8ec8-461f-c467-9208ea89b293"
      },
      "source": [
        " texts = [\n",
        "     \"Alexandra is very proud of herself.\", \"Alexandra is very proud of himself.\",\n",
        "     \"Alexander is very proud of herself.\", \"Alexander is very proud of himself.\",\n",
        "     \"Alexandra is very proud of she.\", \"Alexandra is very proud of her.\",\n",
        "     \"Alexandra is very proud of her son.\"\n",
        " ]\n",
        " tokenizer.pad_token = tokenizer.eos_token\n",
        " batch = tokenizer(texts, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        " # добавляем индекс начала строки (склейка массивов по первой координате)\n",
        " batch[\"input_ids\"] = torch.cat([\n",
        "    torch.ones_like(batch[\"input_ids\"][:,:1])*tokenizer.bos_token_id, \n",
        "    batch[\"input_ids\"]\n",
        " ], dim=1)\n",
        "#  batch[\"attention_mask\"] = torch.cat([\n",
        "#     torch.ones_like(batch[\"attention_mask\"][:,:1]),\n",
        "#     batch[\"attention_mask\"]\n",
        "#  ], dim=-1)\n",
        " with torch.no_grad():\n",
        "    logits = model(batch[\"input_ids\"])[\"logits\"]\n",
        " probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        " print(probs.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 10, 50257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MGAeRn-8_XG",
        "outputId": "0245d5ef-a7b3-4c50-c212-226f70ab761c"
      },
      "source": [
        "for i, text in enumerate(texts):\n",
        "    print(text)\n",
        "    text_token_ids = batch[\"input_ids\"][i,1:]\n",
        "    text_tokens = [x.strip(\"ĠĊ\") for x in tokenizer.convert_ids_to_tokens(text_token_ids)]\n",
        "    for j, (index, token) in enumerate(zip(text_token_ids, text_tokens)):\n",
        "        print(f\"{token}:{probs[i,j,index]:.3f}\", end=\" \")\n",
        "    print(\"\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alexandra is very proud of herself.\n",
            "Alex:0.000 andra:0.050 is:0.014 very:0.004 proud:0.028 of:0.579 herself:0.040 .:0.215 <|endoftext|>:0.002 \n",
            "Alexandra is very proud of himself.\n",
            "Alex:0.000 andra:0.050 is:0.014 very:0.004 proud:0.028 of:0.579 himself:0.002 .:0.213 <|endoftext|>:0.002 \n",
            "Alexander is very proud of herself.\n",
            "Alexander:0.000 is:0.011 very:0.004 proud:0.030 of:0.679 herself:0.001 .:0.205 <|endoftext|>:0.002 <|endoftext|>:0.000 \n",
            "Alexander is very proud of himself.\n",
            "Alexander:0.000 is:0.011 very:0.004 proud:0.030 of:0.679 himself:0.020 .:0.199 <|endoftext|>:0.002 <|endoftext|>:0.000 \n",
            "Alexandra is very proud of she.\n",
            "Alex:0.000 andra:0.050 is:0.014 very:0.004 proud:0.028 of:0.579 she:0.001 .:0.002 <|endoftext|>:0.008 \n",
            "Alexandra is very proud of her.\n",
            "Alex:0.000 andra:0.050 is:0.014 very:0.004 proud:0.028 of:0.579 her:0.356 .:0.005 <|endoftext|>:0.003 \n",
            "Alexandra is very proud of her son.\n",
            "Alex:0.000 andra:0.050 is:0.014 very:0.004 proud:0.028 of:0.579 her:0.356 son:0.009 .:0.165 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78soi70RMdrM"
      },
      "source": [
        "## Writing model for correcting misspelled words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODuUwoMMnNG"
      },
      "source": [
        "Let`s load library with English dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aJN6qXObj9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebcfe5f-fcd6-4e1d-8c81-bd553f3b7999"
      },
      "source": [
        "!apt install -qq enchant\n",
        "!pip install pyenchant"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Collecting pyenchant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f1/162fc6975068098e3327358216b70bbecba1d8004438c3bc8fe9f9378a89/pyenchant-3.2.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdDCH3QFMrU8"
      },
      "source": [
        "Here we write the function for finding misspelled words. If you want to correct not only misprint but also grammatical errors you should comment string (`if not d.check(word_list[i]):`). Unfortunately if you use the free version of colab commenting on the string lead to 'RUNTIME ERROR'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O16wjo8zbU6W"
      },
      "source": [
        "import enchant\n",
        "#function for finding misspeled word in sentence\n",
        "def find_misspeled(sentance):\n",
        "  word_list = sentance.split(' ')\n",
        "  misspelled_words = dict()\n",
        "  #print(len(word_list))\n",
        "  for i in range(len(word_list)):\n",
        "    if not d.check(word_list[i]):\n",
        "      misspelled_words[word_list[i]] = i\n",
        "  return misspelled_words"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl_tF0Xmbnhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35fa21a-b1c2-4bdb-9249-e29fc4779142"
      },
      "source": [
        "#check fuction\n",
        "### check the useful function in package enchant\n",
        "#load english dictionary\n",
        "d = enchant.Dict(\"en_US\")\n",
        "#find misspelled word\n",
        "find_misspeled('He is intelligen')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intelligen': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3jU0f3BKDQN",
        "outputId": "5707449d-195d-43a6-9ae8-e8762d3a842b"
      },
      "source": [
        "#generate possible words\n",
        "d.suggest('intelligen')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['intelligent', 'intelligence', 'intelligible', 'intelligibly', 'belligerent']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS7cUrilOxpN"
      },
      "source": [
        "Here we write a function for generating sentences with possible correct words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Omo8C5b67Z"
      },
      "source": [
        "def generate_correction(sentance):\n",
        "  sentance_list = [sentance]\n",
        "  possible_correction_list = []\n",
        "  word_dict = find_misspeled(sentance)\n",
        "  \n",
        "  for word in word_dict.keys():\n",
        "    for sent in sentance_list:\n",
        "      word_list = sent.split(' ')\n",
        "      for correction_word in d.suggest(word):\n",
        "        new_sentance = ' '.join(word_list[:word_dict[word]] + [correction_word] + word_list[word_dict[word]+1:])\n",
        "        possible_correction_list  += [new_sentance]\n",
        "    #print(sentance_list, word)\n",
        "    sentance_list = possible_correction_list\n",
        "    possible_correction_list = []\n",
        "    #print(sentance_list)\n",
        "  return sentance_list"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhBmfpYvPAss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgMSDvSePBOo"
      },
      "source": [
        "Let`s look at the examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj1uw68ebjBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9619d993-1de5-4f0a-f3ed-614e84273fba"
      },
      "source": [
        " #check function\n",
        " generate_correction('He is intelligen')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He is intelligent',\n",
              " 'He is intelligence',\n",
              " 'He is intelligible',\n",
              " 'He is intelligibly',\n",
              " 'He is belligerent']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZoNhoj4b-yO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd19a6c-cea5-42c8-df6b-4d2593cb2c45"
      },
      "source": [
        "#check function\n",
        "generate_correction('He liks intelligen peaple')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He leeks intelligent people',\n",
              " 'He leeks intelligent Peale',\n",
              " 'He leeks intelligent leaper',\n",
              " 'He leeks intelligent apple',\n",
              " 'He leeks intelligent appeal',\n",
              " 'He leeks intelligence people',\n",
              " 'He leeks intelligence Peale',\n",
              " 'He leeks intelligence leaper',\n",
              " 'He leeks intelligence apple',\n",
              " 'He leeks intelligence appeal',\n",
              " 'He leeks intelligible people',\n",
              " 'He leeks intelligible Peale',\n",
              " 'He leeks intelligible leaper',\n",
              " 'He leeks intelligible apple',\n",
              " 'He leeks intelligible appeal',\n",
              " 'He leeks intelligibly people',\n",
              " 'He leeks intelligibly Peale',\n",
              " 'He leeks intelligibly leaper',\n",
              " 'He leeks intelligibly apple',\n",
              " 'He leeks intelligibly appeal',\n",
              " 'He leeks belligerent people',\n",
              " 'He leeks belligerent Peale',\n",
              " 'He leeks belligerent leaper',\n",
              " 'He leeks belligerent apple',\n",
              " 'He leeks belligerent appeal',\n",
              " 'He ilks intelligent people',\n",
              " 'He ilks intelligent Peale',\n",
              " 'He ilks intelligent leaper',\n",
              " 'He ilks intelligent apple',\n",
              " 'He ilks intelligent appeal',\n",
              " 'He ilks intelligence people',\n",
              " 'He ilks intelligence Peale',\n",
              " 'He ilks intelligence leaper',\n",
              " 'He ilks intelligence apple',\n",
              " 'He ilks intelligence appeal',\n",
              " 'He ilks intelligible people',\n",
              " 'He ilks intelligible Peale',\n",
              " 'He ilks intelligible leaper',\n",
              " 'He ilks intelligible apple',\n",
              " 'He ilks intelligible appeal',\n",
              " 'He ilks intelligibly people',\n",
              " 'He ilks intelligibly Peale',\n",
              " 'He ilks intelligibly leaper',\n",
              " 'He ilks intelligibly apple',\n",
              " 'He ilks intelligibly appeal',\n",
              " 'He ilks belligerent people',\n",
              " 'He ilks belligerent Peale',\n",
              " 'He ilks belligerent leaper',\n",
              " 'He ilks belligerent apple',\n",
              " 'He ilks belligerent appeal',\n",
              " 'He likes intelligent people',\n",
              " 'He likes intelligent Peale',\n",
              " 'He likes intelligent leaper',\n",
              " 'He likes intelligent apple',\n",
              " 'He likes intelligent appeal',\n",
              " 'He likes intelligence people',\n",
              " 'He likes intelligence Peale',\n",
              " 'He likes intelligence leaper',\n",
              " 'He likes intelligence apple',\n",
              " 'He likes intelligence appeal',\n",
              " 'He likes intelligible people',\n",
              " 'He likes intelligible Peale',\n",
              " 'He likes intelligible leaper',\n",
              " 'He likes intelligible apple',\n",
              " 'He likes intelligible appeal',\n",
              " 'He likes intelligibly people',\n",
              " 'He likes intelligibly Peale',\n",
              " 'He likes intelligibly leaper',\n",
              " 'He likes intelligibly apple',\n",
              " 'He likes intelligibly appeal',\n",
              " 'He likes belligerent people',\n",
              " 'He likes belligerent Peale',\n",
              " 'He likes belligerent leaper',\n",
              " 'He likes belligerent apple',\n",
              " 'He likes belligerent appeal',\n",
              " 'He links intelligent people',\n",
              " 'He links intelligent Peale',\n",
              " 'He links intelligent leaper',\n",
              " 'He links intelligent apple',\n",
              " 'He links intelligent appeal',\n",
              " 'He links intelligence people',\n",
              " 'He links intelligence Peale',\n",
              " 'He links intelligence leaper',\n",
              " 'He links intelligence apple',\n",
              " 'He links intelligence appeal',\n",
              " 'He links intelligible people',\n",
              " 'He links intelligible Peale',\n",
              " 'He links intelligible leaper',\n",
              " 'He links intelligible apple',\n",
              " 'He links intelligible appeal',\n",
              " 'He links intelligibly people',\n",
              " 'He links intelligibly Peale',\n",
              " 'He links intelligibly leaper',\n",
              " 'He links intelligibly apple',\n",
              " 'He links intelligibly appeal',\n",
              " 'He links belligerent people',\n",
              " 'He links belligerent Peale',\n",
              " 'He links belligerent leaper',\n",
              " 'He links belligerent apple',\n",
              " 'He links belligerent appeal',\n",
              " 'He licks intelligent people',\n",
              " 'He licks intelligent Peale',\n",
              " 'He licks intelligent leaper',\n",
              " 'He licks intelligent apple',\n",
              " 'He licks intelligent appeal',\n",
              " 'He licks intelligence people',\n",
              " 'He licks intelligence Peale',\n",
              " 'He licks intelligence leaper',\n",
              " 'He licks intelligence apple',\n",
              " 'He licks intelligence appeal',\n",
              " 'He licks intelligible people',\n",
              " 'He licks intelligible Peale',\n",
              " 'He licks intelligible leaper',\n",
              " 'He licks intelligible apple',\n",
              " 'He licks intelligible appeal',\n",
              " 'He licks intelligibly people',\n",
              " 'He licks intelligibly Peale',\n",
              " 'He licks intelligibly leaper',\n",
              " 'He licks intelligibly apple',\n",
              " 'He licks intelligibly appeal',\n",
              " 'He licks belligerent people',\n",
              " 'He licks belligerent Peale',\n",
              " 'He licks belligerent leaper',\n",
              " 'He licks belligerent apple',\n",
              " 'He licks belligerent appeal',\n",
              " 'He like intelligent people',\n",
              " 'He like intelligent Peale',\n",
              " 'He like intelligent leaper',\n",
              " 'He like intelligent apple',\n",
              " 'He like intelligent appeal',\n",
              " 'He like intelligence people',\n",
              " 'He like intelligence Peale',\n",
              " 'He like intelligence leaper',\n",
              " 'He like intelligence apple',\n",
              " 'He like intelligence appeal',\n",
              " 'He like intelligible people',\n",
              " 'He like intelligible Peale',\n",
              " 'He like intelligible leaper',\n",
              " 'He like intelligible apple',\n",
              " 'He like intelligible appeal',\n",
              " 'He like intelligibly people',\n",
              " 'He like intelligibly Peale',\n",
              " 'He like intelligibly leaper',\n",
              " 'He like intelligibly apple',\n",
              " 'He like intelligibly appeal',\n",
              " 'He like belligerent people',\n",
              " 'He like belligerent Peale',\n",
              " 'He like belligerent leaper',\n",
              " 'He like belligerent apple',\n",
              " 'He like belligerent appeal',\n",
              " 'He lies intelligent people',\n",
              " 'He lies intelligent Peale',\n",
              " 'He lies intelligent leaper',\n",
              " 'He lies intelligent apple',\n",
              " 'He lies intelligent appeal',\n",
              " 'He lies intelligence people',\n",
              " 'He lies intelligence Peale',\n",
              " 'He lies intelligence leaper',\n",
              " 'He lies intelligence apple',\n",
              " 'He lies intelligence appeal',\n",
              " 'He lies intelligible people',\n",
              " 'He lies intelligible Peale',\n",
              " 'He lies intelligible leaper',\n",
              " 'He lies intelligible apple',\n",
              " 'He lies intelligible appeal',\n",
              " 'He lies intelligibly people',\n",
              " 'He lies intelligibly Peale',\n",
              " 'He lies intelligibly leaper',\n",
              " 'He lies intelligibly apple',\n",
              " 'He lies intelligibly appeal',\n",
              " 'He lies belligerent people',\n",
              " 'He lies belligerent Peale',\n",
              " 'He lies belligerent leaper',\n",
              " 'He lies belligerent apple',\n",
              " 'He lies belligerent appeal',\n",
              " 'He oiks intelligent people',\n",
              " 'He oiks intelligent Peale',\n",
              " 'He oiks intelligent leaper',\n",
              " 'He oiks intelligent apple',\n",
              " 'He oiks intelligent appeal',\n",
              " 'He oiks intelligence people',\n",
              " 'He oiks intelligence Peale',\n",
              " 'He oiks intelligence leaper',\n",
              " 'He oiks intelligence apple',\n",
              " 'He oiks intelligence appeal',\n",
              " 'He oiks intelligible people',\n",
              " 'He oiks intelligible Peale',\n",
              " 'He oiks intelligible leaper',\n",
              " 'He oiks intelligible apple',\n",
              " 'He oiks intelligible appeal',\n",
              " 'He oiks intelligibly people',\n",
              " 'He oiks intelligibly Peale',\n",
              " 'He oiks intelligibly leaper',\n",
              " 'He oiks intelligibly apple',\n",
              " 'He oiks intelligibly appeal',\n",
              " 'He oiks belligerent people',\n",
              " 'He oiks belligerent Peale',\n",
              " 'He oiks belligerent leaper',\n",
              " 'He oiks belligerent apple',\n",
              " 'He oiks belligerent appeal',\n",
              " 'He lids intelligent people',\n",
              " 'He lids intelligent Peale',\n",
              " 'He lids intelligent leaper',\n",
              " 'He lids intelligent apple',\n",
              " 'He lids intelligent appeal',\n",
              " 'He lids intelligence people',\n",
              " 'He lids intelligence Peale',\n",
              " 'He lids intelligence leaper',\n",
              " 'He lids intelligence apple',\n",
              " 'He lids intelligence appeal',\n",
              " 'He lids intelligible people',\n",
              " 'He lids intelligible Peale',\n",
              " 'He lids intelligible leaper',\n",
              " 'He lids intelligible apple',\n",
              " 'He lids intelligible appeal',\n",
              " 'He lids intelligibly people',\n",
              " 'He lids intelligibly Peale',\n",
              " 'He lids intelligibly leaper',\n",
              " 'He lids intelligibly apple',\n",
              " 'He lids intelligibly appeal',\n",
              " 'He lids belligerent people',\n",
              " 'He lids belligerent Peale',\n",
              " 'He lids belligerent leaper',\n",
              " 'He lids belligerent apple',\n",
              " 'He lids belligerent appeal',\n",
              " 'He lips intelligent people',\n",
              " 'He lips intelligent Peale',\n",
              " 'He lips intelligent leaper',\n",
              " 'He lips intelligent apple',\n",
              " 'He lips intelligent appeal',\n",
              " 'He lips intelligence people',\n",
              " 'He lips intelligence Peale',\n",
              " 'He lips intelligence leaper',\n",
              " 'He lips intelligence apple',\n",
              " 'He lips intelligence appeal',\n",
              " 'He lips intelligible people',\n",
              " 'He lips intelligible Peale',\n",
              " 'He lips intelligible leaper',\n",
              " 'He lips intelligible apple',\n",
              " 'He lips intelligible appeal',\n",
              " 'He lips intelligibly people',\n",
              " 'He lips intelligibly Peale',\n",
              " 'He lips intelligibly leaper',\n",
              " 'He lips intelligibly apple',\n",
              " 'He lips intelligibly appeal',\n",
              " 'He lips belligerent people',\n",
              " 'He lips belligerent Peale',\n",
              " 'He lips belligerent leaper',\n",
              " 'He lips belligerent apple',\n",
              " 'He lips belligerent appeal']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lojfRM5cBql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480e09aa-2262-44f5-9f98-967acc4f1af8"
      },
      "source": [
        " texts = generate_correction('He liks intelligen peaple')\n",
        " tokenizer.pad_token = tokenizer.eos_token\n",
        " batch = tokenizer(texts, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        " # добавляем индекс начала строки (склейка массивов по первой координате)\n",
        " batch[\"input_ids\"] = torch.cat([\n",
        "    torch.ones_like(batch[\"input_ids\"][:,:1])*tokenizer.bos_token_id, \n",
        "    batch[\"input_ids\"]\n",
        " ], dim=1)\n",
        "#  batch[\"attention_mask\"] = torch.cat([\n",
        "#     torch.ones_like(batch[\"attention_mask\"][:,:1]),\n",
        "#     batch[\"attention_mask\"]\n",
        "#  ], dim=-1)\n",
        " with torch.no_grad():\n",
        "    logits = model(batch[\"input_ids\"])[\"logits\"]\n",
        " probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        " print(probs.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250, 9, 50257)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH7NwwgyP4v8"
      },
      "source": [
        "Here we write code that for each subtokens in a sentence shows its logarithm of possibility to appear in the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROOIOmk7dN5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1093d581-f8a5-44d5-d0af-d964915acdd4"
      },
      "source": [
        "\n",
        "for i, text in enumerate(texts):\n",
        "    print(text)\n",
        "    text_token_ids = batch[\"input_ids\"][i,1:]\n",
        "    text_tokens = [x.strip(\"ĠĊ\") for x in tokenizer.convert_ids_to_tokens(text_token_ids)]\n",
        "    for j, (index, token) in enumerate(zip(text_token_ids, text_tokens)):\n",
        "        if token != '<|endoftext|>':\n",
        "          print(f\"{token}:{math.log10(probs[i,j,index]):.3f}\", end=\" \")\n",
        "    print(\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He leeks intelligent people\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligent:-5.550 people:-2.089 \n",
            "He leeks intelligent Peale\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligent:-5.550 Pe:-5.157 ale:-3.447 \n",
            "He leeks intelligent leaper\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligent:-5.550 le:-3.197 aper:-4.373 \n",
            "He leeks intelligent apple\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligent:-5.550 apple:-4.334 \n",
            "He leeks intelligent appeal\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligent:-5.550 appeal:-4.481 \n",
            "He leeks intelligence people\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligence:-4.806 people:-3.943 \n",
            "He leeks intelligence Peale\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligence:-4.806 Pe:-5.932 ale:-3.097 \n",
            "He leeks intelligence leaper\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligence:-4.806 le:-3.803 aper:-4.011 \n",
            "He leeks intelligence apple\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligence:-4.806 apple:-5.632 \n",
            "He leeks intelligence appeal\n",
            "He:-2.584 le:-4.359 eks:-3.924 intelligence:-4.806 appeal:-5.404 \n",
            "He leeks intelligible people\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ible:-2.737 people:-3.696 \n",
            "He leeks intelligible Peale\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ible:-2.737 Pe:-4.762 ale:-3.450 \n",
            "He leeks intelligible leaper\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ible:-2.737 le:-3.174 aper:-4.341 \n",
            "He leeks intelligible apple\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ible:-2.737 apple:-4.016 \n",
            "He leeks intelligible appeal\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ible:-2.737 appeal:-4.813 \n",
            "He leeks intelligibly people\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ibly:-1.813 people:-5.261 \n",
            "He leeks intelligibly Peale\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ibly:-1.813 Pe:-6.633 ale:-3.270 \n",
            "He leeks intelligibly leaper\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ibly:-1.813 le:-4.939 aper:-3.863 \n",
            "He leeks intelligibly apple\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ibly:-1.813 apple:-6.672 \n",
            "He leeks intelligibly appeal\n",
            "He:-2.584 le:-4.359 eks:-3.924 intellig:-5.820 ibly:-1.813 appeal:-6.996 \n",
            "He leeks belligerent people\n",
            "He:-2.584 le:-4.359 eks:-3.924 bellig:-6.071 erent:-0.019 people:-4.765 \n",
            "He leeks belligerent Peale\n",
            "He:-2.584 le:-4.359 eks:-3.924 bellig:-6.071 erent:-0.019 Pe:-5.663 ale:-3.131 \n",
            "He leeks belligerent leaper\n",
            "He:-2.584 le:-4.359 eks:-3.924 bellig:-6.071 erent:-0.019 le:-4.542 aper:-4.709 \n",
            "He leeks belligerent apple\n",
            "He:-2.584 le:-4.359 eks:-3.924 bellig:-6.071 erent:-0.019 apple:-6.076 \n",
            "He leeks belligerent appeal\n",
            "He:-2.584 le:-4.359 eks:-3.924 bellig:-6.071 erent:-0.019 appeal:-5.235 \n",
            "He ilks intelligent people\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligent:-5.774 people:-1.230 \n",
            "He ilks intelligent Peale\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligent:-5.774 Pe:-5.214 ale:-2.928 \n",
            "He ilks intelligent leaper\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligent:-5.774 le:-3.897 aper:-3.061 \n",
            "He ilks intelligent apple\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligent:-5.774 apple:-5.305 \n",
            "He ilks intelligent appeal\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligent:-5.774 appeal:-4.908 \n",
            "He ilks intelligence people\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligence:-5.652 people:-2.193 \n",
            "He ilks intelligence Peale\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligence:-5.652 Pe:-5.866 ale:-2.637 \n",
            "He ilks intelligence leaper\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligence:-5.652 le:-2.391 aper:-3.040 \n",
            "He ilks intelligence apple\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligence:-5.652 apple:-5.287 \n",
            "He ilks intelligence appeal\n",
            "He:-2.584 il:-6.233 ks:-1.851 intelligence:-5.652 appeal:-5.205 \n",
            "He ilks intelligible people\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ible:-1.274 people:-1.561 \n",
            "He ilks intelligible Peale\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ible:-1.274 Pe:-5.177 ale:-2.868 \n",
            "He ilks intelligible leaper\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ible:-1.274 le:-4.495 aper:-3.438 \n",
            "He ilks intelligible apple\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ible:-1.274 apple:-5.647 \n",
            "He ilks intelligible appeal\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ible:-1.274 appeal:-4.321 \n",
            "He ilks intelligibly people\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ibly:-1.561 people:-3.770 \n",
            "He ilks intelligibly Peale\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ibly:-1.561 Pe:-6.691 ale:-2.619 \n",
            "He ilks intelligibly leaper\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ibly:-1.561 le:-4.416 aper:-3.699 \n",
            "He ilks intelligibly apple\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ibly:-1.561 apple:-6.279 \n",
            "He ilks intelligibly appeal\n",
            "He:-2.584 il:-6.233 ks:-1.851 intellig:-5.685 ibly:-1.561 appeal:-3.756 \n",
            "He ilks belligerent people\n",
            "He:-2.584 il:-6.233 ks:-1.851 bellig:-5.995 erent:-0.018 people:-2.501 \n",
            "He ilks belligerent Peale\n",
            "He:-2.584 il:-6.233 ks:-1.851 bellig:-5.995 erent:-0.018 Pe:-4.827 ale:-2.747 \n",
            "He ilks belligerent leaper\n",
            "He:-2.584 il:-6.233 ks:-1.851 bellig:-5.995 erent:-0.018 le:-4.070 aper:-3.496 \n",
            "He ilks belligerent apple\n",
            "He:-2.584 il:-6.233 ks:-1.851 bellig:-5.995 erent:-0.018 apple:-6.010 \n",
            "He ilks belligerent appeal\n",
            "He:-2.584 il:-6.233 ks:-1.851 bellig:-5.995 erent:-0.018 appeal:-4.742 \n",
            "He likes intelligent people\n",
            "He:-2.584 likes:-2.974 intelligent:-4.925 people:-0.377 \n",
            "He likes intelligent Peale\n",
            "He:-2.584 likes:-2.974 intelligent:-4.925 Pe:-5.661 ale:-3.502 \n",
            "He likes intelligent leaper\n",
            "He:-2.584 likes:-2.974 intelligent:-4.925 le:-4.140 aper:-2.897 \n",
            "He likes intelligent apple\n",
            "He:-2.584 likes:-2.974 intelligent:-4.925 apple:-4.722 \n",
            "He likes intelligent appeal\n",
            "He:-2.584 likes:-2.974 intelligent:-4.925 appeal:-4.408 \n",
            "He likes intelligence people\n",
            "He:-2.584 likes:-2.974 intelligence:-4.751 people:-2.395 \n",
            "He likes intelligence Peale\n",
            "He:-2.584 likes:-2.974 intelligence:-4.751 Pe:-5.838 ale:-3.099 \n",
            "He likes intelligence leaper\n",
            "He:-2.584 likes:-2.974 intelligence:-4.751 le:-3.749 aper:-3.453 \n",
            "He likes intelligence apple\n",
            "He:-2.584 likes:-2.974 intelligence:-4.751 apple:-6.114 \n",
            "He likes intelligence appeal\n",
            "He:-2.584 likes:-2.974 intelligence:-4.751 appeal:-5.211 \n",
            "He likes intelligible people\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ible:-1.229 people:-1.598 \n",
            "He likes intelligible Peale\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ible:-1.229 Pe:-5.579 ale:-3.814 \n",
            "He likes intelligible leaper\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ible:-1.229 le:-4.191 aper:-4.062 \n",
            "He likes intelligible apple\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ible:-1.229 apple:-4.788 \n",
            "He likes intelligible appeal\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ible:-1.229 appeal:-4.333 \n",
            "He likes intelligibly people\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ibly:-2.494 people:-3.647 \n",
            "He likes intelligibly Peale\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ibly:-2.494 Pe:-6.103 ale:-3.401 \n",
            "He likes intelligibly leaper\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ibly:-2.494 le:-3.975 aper:-4.271 \n",
            "He likes intelligibly apple\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ibly:-2.494 apple:-5.403 \n",
            "He likes intelligibly appeal\n",
            "He:-2.584 likes:-2.974 intellig:-6.539 ibly:-2.494 appeal:-5.447 \n",
            "He likes belligerent people\n",
            "He:-2.584 likes:-2.974 bellig:-6.166 erent:-0.071 people:-1.420 \n",
            "He likes belligerent Peale\n",
            "He:-2.584 likes:-2.974 bellig:-6.166 erent:-0.071 Pe:-4.673 ale:-3.071 \n",
            "He likes belligerent leaper\n",
            "He:-2.584 likes:-2.974 bellig:-6.166 erent:-0.071 le:-3.891 aper:-3.831 \n",
            "He likes belligerent apple\n",
            "He:-2.584 likes:-2.974 bellig:-6.166 erent:-0.071 apple:-5.124 \n",
            "He likes belligerent appeal\n",
            "He:-2.584 likes:-2.974 bellig:-6.166 erent:-0.071 appeal:-4.359 \n",
            "He links intelligent people\n",
            "He:-2.584 links:-4.881 intelligent:-4.560 people:-1.069 \n",
            "He links intelligent Peale\n",
            "He:-2.584 links:-4.881 intelligent:-4.560 Pe:-5.793 ale:-3.175 \n",
            "He links intelligent leaper\n",
            "He:-2.584 links:-4.881 intelligent:-4.560 le:-3.975 aper:-3.143 \n",
            "He links intelligent apple\n",
            "He:-2.584 links:-4.881 intelligent:-4.560 apple:-5.174 \n",
            "He links intelligent appeal\n",
            "He:-2.584 links:-4.881 intelligent:-4.560 appeal:-3.728 \n",
            "He links intelligence people\n",
            "He:-2.584 links:-4.881 intelligence:-3.543 people:-3.559 \n",
            "He links intelligence Peale\n",
            "He:-2.584 links:-4.881 intelligence:-3.543 Pe:-6.724 ale:-3.013 \n",
            "He links intelligence leaper\n",
            "He:-2.584 links:-4.881 intelligence:-3.543 le:-3.172 aper:-4.520 \n",
            "He links intelligence apple\n",
            "He:-2.584 links:-4.881 intelligence:-3.543 apple:-6.453 \n",
            "He links intelligence appeal\n",
            "He:-2.584 links:-4.881 intelligence:-3.543 appeal:-5.408 \n",
            "He links intelligible people\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ible:-1.665 people:-2.521 \n",
            "He links intelligible Peale\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ible:-1.665 Pe:-5.593 ale:-3.412 \n",
            "He links intelligible leaper\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ible:-1.665 le:-4.262 aper:-4.042 \n",
            "He links intelligible apple\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ible:-1.665 apple:-5.053 \n",
            "He links intelligible appeal\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ible:-1.665 appeal:-3.892 \n",
            "He links intelligibly people\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ibly:-2.374 people:-4.397 \n",
            "He links intelligibly Peale\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ibly:-2.374 Pe:-6.735 ale:-3.122 \n",
            "He links intelligibly leaper\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ibly:-2.374 le:-5.764 aper:-4.297 \n",
            "He links intelligibly apple\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ibly:-2.374 apple:-6.963 \n",
            "He links intelligibly appeal\n",
            "He:-2.584 links:-4.881 intellig:-4.945 ibly:-2.374 appeal:-6.222 \n",
            "He links belligerent people\n",
            "He:-2.584 links:-4.881 bellig:-5.756 erent:-0.102 people:-2.444 \n",
            "He links belligerent Peale\n",
            "He:-2.584 links:-4.881 bellig:-5.756 erent:-0.102 Pe:-4.386 ale:-2.949 \n",
            "He links belligerent leaper\n",
            "He:-2.584 links:-4.881 bellig:-5.756 erent:-0.102 le:-4.004 aper:-3.989 \n",
            "He links belligerent apple\n",
            "He:-2.584 links:-4.881 bellig:-5.756 erent:-0.102 apple:-5.539 \n",
            "He links belligerent appeal\n",
            "He:-2.584 links:-4.881 bellig:-5.756 erent:-0.102 appeal:-4.098 \n",
            "He licks intelligent people\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligent:-6.899 people:-1.458 \n",
            "He licks intelligent Peale\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligent:-6.899 Pe:-5.150 ale:-3.108 \n",
            "He licks intelligent leaper\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligent:-6.899 le:-3.484 aper:-3.413 \n",
            "He licks intelligent apple\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligent:-6.899 apple:-3.616 \n",
            "He licks intelligent appeal\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligent:-6.899 appeal:-5.076 \n",
            "He licks intelligence people\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligence:-6.069 people:-3.543 \n",
            "He licks intelligence Peale\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligence:-6.069 Pe:-5.984 ale:-2.794 \n",
            "He licks intelligence leaper\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligence:-6.069 le:-3.917 aper:-3.794 \n",
            "He licks intelligence apple\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligence:-6.069 apple:-4.505 \n",
            "He licks intelligence appeal\n",
            "He:-2.584 l:-3.850 icks:-1.621 intelligence:-6.069 appeal:-5.390 \n",
            "He licks intelligible people\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ible:-2.733 people:-3.218 \n",
            "He licks intelligible Peale\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ible:-2.733 Pe:-5.282 ale:-3.315 \n",
            "He licks intelligible leaper\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ible:-2.733 le:-3.678 aper:-4.295 \n",
            "He licks intelligible apple\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ible:-2.733 apple:-3.633 \n",
            "He licks intelligible appeal\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ible:-2.733 appeal:-5.365 \n",
            "He licks intelligibly people\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ibly:-1.954 people:-4.702 \n",
            "He licks intelligibly Peale\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ibly:-1.954 Pe:-6.663 ale:-2.987 \n",
            "He licks intelligibly leaper\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ibly:-1.954 le:-5.039 aper:-3.943 \n",
            "He licks intelligibly apple\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ibly:-1.954 apple:-6.163 \n",
            "He licks intelligibly appeal\n",
            "He:-2.584 l:-3.850 icks:-1.621 intellig:-6.824 ibly:-1.954 appeal:-6.805 \n",
            "He licks belligerent people\n",
            "He:-2.584 l:-3.850 icks:-1.621 bellig:-6.908 erent:-0.001 people:-3.722 \n",
            "He licks belligerent Peale\n",
            "He:-2.584 l:-3.850 icks:-1.621 bellig:-6.908 erent:-0.001 Pe:-5.049 ale:-2.951 \n",
            "He licks belligerent leaper\n",
            "He:-2.584 l:-3.850 icks:-1.621 bellig:-6.908 erent:-0.001 le:-4.624 aper:-3.916 \n",
            "He licks belligerent apple\n",
            "He:-2.584 l:-3.850 icks:-1.621 bellig:-6.908 erent:-0.001 apple:-5.034 \n",
            "He licks belligerent appeal\n",
            "He:-2.584 l:-3.850 icks:-1.621 bellig:-6.908 erent:-0.001 appeal:-5.489 \n",
            "He like intelligent people\n",
            "He:-2.584 like:-4.377 intelligent:-4.702 people:-0.377 \n",
            "He like intelligent Peale\n",
            "He:-2.584 like:-4.377 intelligent:-4.702 Pe:-5.360 ale:-3.189 \n",
            "He like intelligent leaper\n",
            "He:-2.584 like:-4.377 intelligent:-4.702 le:-4.105 aper:-2.815 \n",
            "He like intelligent apple\n",
            "He:-2.584 like:-4.377 intelligent:-4.702 apple:-4.878 \n",
            "He like intelligent appeal\n",
            "He:-2.584 like:-4.377 intelligent:-4.702 appeal:-4.457 \n",
            "He like intelligence people\n",
            "He:-2.584 like:-4.377 intelligence:-4.562 people:-1.929 \n",
            "He like intelligence Peale\n",
            "He:-2.584 like:-4.377 intelligence:-4.562 Pe:-5.666 ale:-3.089 \n",
            "He like intelligence leaper\n",
            "He:-2.584 like:-4.377 intelligence:-4.562 le:-3.336 aper:-3.452 \n",
            "He like intelligence apple\n",
            "He:-2.584 like:-4.377 intelligence:-4.562 apple:-5.735 \n",
            "He like intelligence appeal\n",
            "He:-2.584 like:-4.377 intelligence:-4.562 appeal:-5.033 \n",
            "He like intelligible people\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ible:-1.423 people:-1.507 \n",
            "He like intelligible Peale\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ible:-1.423 Pe:-5.380 ale:-3.454 \n",
            "He like intelligible leaper\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ible:-1.423 le:-4.219 aper:-4.013 \n",
            "He like intelligible apple\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ible:-1.423 apple:-4.865 \n",
            "He like intelligible appeal\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ible:-1.423 appeal:-4.268 \n",
            "He like intelligibly people\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ibly:-2.362 people:-3.628 \n",
            "He like intelligibly Peale\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ibly:-2.362 Pe:-6.299 ale:-3.113 \n",
            "He like intelligibly leaper\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ibly:-2.362 le:-4.107 aper:-4.201 \n",
            "He like intelligibly apple\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ibly:-2.362 apple:-5.649 \n",
            "He like intelligibly appeal\n",
            "He:-2.584 like:-4.377 intellig:-6.149 ibly:-2.362 appeal:-5.228 \n",
            "He like belligerent people\n",
            "He:-2.584 like:-4.377 bellig:-6.169 erent:-0.076 people:-1.422 \n",
            "He like belligerent Peale\n",
            "He:-2.584 like:-4.377 bellig:-6.169 erent:-0.076 Pe:-4.477 ale:-2.921 \n",
            "He like belligerent leaper\n",
            "He:-2.584 like:-4.377 bellig:-6.169 erent:-0.076 le:-3.808 aper:-3.700 \n",
            "He like belligerent apple\n",
            "He:-2.584 like:-4.377 bellig:-6.169 erent:-0.076 apple:-5.272 \n",
            "He like belligerent appeal\n",
            "He:-2.584 like:-4.377 bellig:-6.169 erent:-0.076 appeal:-4.354 \n",
            "He lies intelligent people\n",
            "He:-2.584 lies:-3.943 intelligent:-5.869 people:-2.984 \n",
            "He lies intelligent Peale\n",
            "He:-2.584 lies:-3.943 intelligent:-5.869 Pe:-6.222 ale:-2.789 \n",
            "He lies intelligent leaper\n",
            "He:-2.584 lies:-3.943 intelligent:-5.869 le:-5.518 aper:-2.772 \n",
            "He lies intelligent apple\n",
            "He:-2.584 lies:-3.943 intelligent:-5.869 apple:-6.706 \n",
            "He lies intelligent appeal\n",
            "He:-2.584 lies:-3.943 intelligent:-5.869 appeal:-6.051 \n",
            "He lies intelligence people\n",
            "He:-2.584 lies:-3.943 intelligence:-6.331 people:-3.399 \n",
            "He lies intelligence Peale\n",
            "He:-2.584 lies:-3.943 intelligence:-6.331 Pe:-6.339 ale:-2.755 \n",
            "He lies intelligence leaper\n",
            "He:-2.584 lies:-3.943 intelligence:-6.331 le:-2.975 aper:-2.917 \n",
            "He lies intelligence apple\n",
            "He:-2.584 lies:-3.943 intelligence:-6.331 apple:-5.468 \n",
            "He lies intelligence appeal\n",
            "He:-2.584 lies:-3.943 intelligence:-6.331 appeal:-4.979 \n",
            "He lies intelligible people\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ible:-3.545 people:-3.874 \n",
            "He lies intelligible Peale\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ible:-3.545 Pe:-6.381 ale:-2.871 \n",
            "He lies intelligible leaper\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ible:-3.545 le:-5.463 aper:-3.761 \n",
            "He lies intelligible apple\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ible:-3.545 apple:-6.624 \n",
            "He lies intelligible appeal\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ible:-3.545 appeal:-5.445 \n",
            "He lies intelligibly people\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ibly:-2.215 people:-5.177 \n",
            "He lies intelligibly Peale\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ibly:-2.215 Pe:-7.569 ale:-2.897 \n",
            "He lies intelligibly leaper\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ibly:-2.215 le:-5.000 aper:-4.753 \n",
            "He lies intelligibly apple\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ibly:-2.215 apple:-7.204 \n",
            "He lies intelligibly appeal\n",
            "He:-2.584 lies:-3.943 intellig:-6.243 ibly:-2.215 appeal:-6.390 \n",
            "He lies belligerent people\n",
            "He:-2.584 lies:-3.943 bellig:-5.454 erent:-0.000 people:-4.980 \n",
            "He lies belligerent Peale\n",
            "He:-2.584 lies:-3.943 bellig:-5.454 erent:-0.000 Pe:-6.766 ale:-2.719 \n",
            "He lies belligerent leaper\n",
            "He:-2.584 lies:-3.943 bellig:-5.454 erent:-0.000 le:-5.443 aper:-4.039 \n",
            "He lies belligerent apple\n",
            "He:-2.584 lies:-3.943 bellig:-5.454 erent:-0.000 apple:-7.544 \n",
            "He lies belligerent appeal\n",
            "He:-2.584 lies:-3.943 bellig:-5.454 erent:-0.000 appeal:-6.065 \n",
            "He oiks intelligent people\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligent:-5.240 people:-1.376 \n",
            "He oiks intelligent Peale\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligent:-5.240 Pe:-4.977 ale:-3.260 \n",
            "He oiks intelligent leaper\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligent:-5.240 le:-3.410 aper:-3.111 \n",
            "He oiks intelligent apple\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligent:-5.240 apple:-4.306 \n",
            "He oiks intelligent appeal\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligent:-5.240 appeal:-3.721 \n",
            "He oiks intelligence people\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligence:-4.871 people:-2.883 \n",
            "He oiks intelligence Peale\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligence:-4.871 Pe:-5.424 ale:-3.065 \n",
            "He oiks intelligence leaper\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligence:-4.871 le:-3.066 aper:-3.526 \n",
            "He oiks intelligence apple\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligence:-4.871 apple:-5.256 \n",
            "He oiks intelligence appeal\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intelligence:-4.871 appeal:-4.338 \n",
            "He oiks intelligible people\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ible:-1.192 people:-2.549 \n",
            "He oiks intelligible Peale\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ible:-1.192 Pe:-4.990 ale:-3.231 \n",
            "He oiks intelligible leaper\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ible:-1.192 le:-3.780 aper:-3.619 \n",
            "He oiks intelligible apple\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ible:-1.192 apple:-4.862 \n",
            "He oiks intelligible appeal\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ible:-1.192 appeal:-3.852 \n",
            "He oiks intelligibly people\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ibly:-1.735 people:-3.572 \n",
            "He oiks intelligibly Peale\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ibly:-1.735 Pe:-5.514 ale:-3.033 \n",
            "He oiks intelligibly leaper\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ibly:-1.735 le:-4.311 aper:-3.506 \n",
            "He oiks intelligibly apple\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ibly:-1.735 apple:-6.140 \n",
            "He oiks intelligibly appeal\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 intellig:-6.138 ibly:-1.735 appeal:-5.029 \n",
            "He oiks belligerent people\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 bellig:-5.785 erent:-0.093 people:-2.791 \n",
            "He oiks belligerent Peale\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 bellig:-5.785 erent:-0.093 Pe:-4.501 ale:-3.034 \n",
            "He oiks belligerent leaper\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 bellig:-5.785 erent:-0.093 le:-3.502 aper:-3.615 \n",
            "He oiks belligerent apple\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 bellig:-5.785 erent:-0.093 apple:-5.187 \n",
            "He oiks belligerent appeal\n",
            "He:-2.584 o:-5.055 i:-2.598 ks:-2.887 bellig:-5.785 erent:-0.093 appeal:-3.797 \n",
            "He lids intelligent people\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligent:-5.988 people:-1.092 \n",
            "He lids intelligent Peale\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligent:-5.988 Pe:-5.095 ale:-3.313 \n",
            "He lids intelligent leaper\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligent:-5.988 le:-3.670 aper:-2.833 \n",
            "He lids intelligent apple\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligent:-5.988 apple:-4.755 \n",
            "He lids intelligent appeal\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligent:-5.988 appeal:-4.901 \n",
            "He lids intelligence people\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligence:-5.502 people:-3.159 \n",
            "He lids intelligence Peale\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligence:-5.502 Pe:-5.652 ale:-2.857 \n",
            "He lids intelligence leaper\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligence:-5.502 le:-3.519 aper:-3.007 \n",
            "He lids intelligence apple\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligence:-5.502 apple:-5.757 \n",
            "He lids intelligence appeal\n",
            "He:-2.584 l:-3.850 ids:-3.163 intelligence:-5.502 appeal:-5.278 \n",
            "He lids intelligible people\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ible:-2.240 people:-2.936 \n",
            "He lids intelligible Peale\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ible:-2.240 Pe:-5.123 ale:-3.264 \n",
            "He lids intelligible leaper\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ible:-2.240 le:-3.946 aper:-3.773 \n",
            "He lids intelligible apple\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ible:-2.240 apple:-4.814 \n",
            "He lids intelligible appeal\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ible:-2.240 appeal:-4.849 \n",
            "He lids intelligibly people\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ibly:-1.724 people:-4.373 \n",
            "He lids intelligibly Peale\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ibly:-1.724 Pe:-6.475 ale:-2.909 \n",
            "He lids intelligibly leaper\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ibly:-1.724 le:-5.074 aper:-3.526 \n",
            "He lids intelligibly apple\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ibly:-1.724 apple:-6.730 \n",
            "He lids intelligibly appeal\n",
            "He:-2.584 l:-3.850 ids:-3.163 intellig:-5.773 ibly:-1.724 appeal:-6.129 \n",
            "He lids belligerent people\n",
            "He:-2.584 l:-3.850 ids:-3.163 bellig:-6.421 erent:-0.010 people:-2.391 \n",
            "He lids belligerent Peale\n",
            "He:-2.584 l:-3.850 ids:-3.163 bellig:-6.421 erent:-0.010 Pe:-4.466 ale:-3.001 \n",
            "He lids belligerent leaper\n",
            "He:-2.584 l:-3.850 ids:-3.163 bellig:-6.421 erent:-0.010 le:-4.051 aper:-3.529 \n",
            "He lids belligerent apple\n",
            "He:-2.584 l:-3.850 ids:-3.163 bellig:-6.421 erent:-0.010 apple:-5.502 \n",
            "He lids belligerent appeal\n",
            "He:-2.584 l:-3.850 ids:-3.163 bellig:-6.421 erent:-0.010 appeal:-4.780 \n",
            "He lips intelligent people\n",
            "He:-2.584 lips:-6.744 intelligent:-5.587 people:-1.962 \n",
            "He lips intelligent Peale\n",
            "He:-2.584 lips:-6.744 intelligent:-5.587 Pe:-4.842 ale:-3.094 \n",
            "He lips intelligent leaper\n",
            "He:-2.584 lips:-6.744 intelligent:-5.587 le:-3.492 aper:-3.675 \n",
            "He lips intelligent apple\n",
            "He:-2.584 lips:-6.744 intelligent:-5.587 apple:-4.110 \n",
            "He lips intelligent appeal\n",
            "He:-2.584 lips:-6.744 intelligent:-5.587 appeal:-4.096 \n",
            "He lips intelligence people\n",
            "He:-2.584 lips:-6.744 intelligence:-5.111 people:-3.565 \n",
            "He lips intelligence Peale\n",
            "He:-2.584 lips:-6.744 intelligence:-5.111 Pe:-5.347 ale:-2.890 \n",
            "He lips intelligence leaper\n",
            "He:-2.584 lips:-6.744 intelligence:-5.111 le:-4.205 aper:-3.326 \n",
            "He lips intelligence apple\n",
            "He:-2.584 lips:-6.744 intelligence:-5.111 apple:-4.718 \n",
            "He lips intelligence appeal\n",
            "He:-2.584 lips:-6.744 intelligence:-5.111 appeal:-4.865 \n",
            "He lips intelligible people\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ible:-2.614 people:-3.486 \n",
            "He lips intelligible Peale\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ible:-2.614 Pe:-4.954 ale:-3.088 \n",
            "He lips intelligible leaper\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ible:-2.614 le:-3.848 aper:-4.377 \n",
            "He lips intelligible apple\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ible:-2.614 apple:-4.207 \n",
            "He lips intelligible appeal\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ible:-2.614 appeal:-4.471 \n",
            "He lips intelligibly people\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ibly:-1.761 people:-4.900 \n",
            "He lips intelligibly Peale\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ibly:-1.761 Pe:-6.524 ale:-2.940 \n",
            "He lips intelligibly leaper\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ibly:-1.761 le:-4.667 aper:-4.018 \n",
            "He lips intelligibly apple\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ibly:-1.761 apple:-6.266 \n",
            "He lips intelligibly appeal\n",
            "He:-2.584 lips:-6.744 intellig:-5.569 ibly:-1.761 appeal:-5.635 \n",
            "He lips belligerent people\n",
            "He:-2.584 lips:-6.744 bellig:-6.355 erent:-0.013 people:-4.762 \n",
            "He lips belligerent Peale\n",
            "He:-2.584 lips:-6.744 bellig:-6.355 erent:-0.013 Pe:-5.240 ale:-2.884 \n",
            "He lips belligerent leaper\n",
            "He:-2.584 lips:-6.744 bellig:-6.355 erent:-0.013 le:-4.936 aper:-4.570 \n",
            "He lips belligerent apple\n",
            "He:-2.584 lips:-6.744 bellig:-6.355 erent:-0.013 apple:-6.082 \n",
            "He lips belligerent appeal\n",
            "He:-2.584 lips:-6.744 bellig:-6.355 erent:-0.013 appeal:-4.919 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_lX6MRNP9bf"
      },
      "source": [
        "So to find our correct sentance we should sum all logarithm of the possibility of each subtokens unless '<|endoftext|>' and find sentences with the max possibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzP1XRg_h2uY"
      },
      "source": [
        "def generate_possible_sentence(sentance, best_three = False):\n",
        "  texts = generate_correction(sentance)\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  batch = tokenizer(texts, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
        "  # добавляем индекс начала строки (склейка массивов по первой координате)\n",
        "  batch[\"input_ids\"] = torch.cat([\n",
        "      torch.ones_like(batch[\"input_ids\"][:,:1])*tokenizer.bos_token_id, \n",
        "      batch[\"input_ids\"]\n",
        "  ], dim=1)\n",
        "  #  batch[\"attention_mask\"] = torch.cat([\n",
        "  #     torch.ones_like(batch[\"attention_mask\"][:,:1]),\n",
        "  #     batch[\"attention_mask\"]\n",
        "  #  ], dim=-1)\n",
        "  with torch.no_grad():\n",
        "      logits = model(batch[\"input_ids\"])[\"logits\"]\n",
        "  probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "  #print(probs.shape)\n",
        "  sentence_probability = dict()\n",
        "  for i, text in enumerate(texts):\n",
        "      #print(text)\n",
        "      s = 1\n",
        "      \n",
        "      text_token_ids = batch[\"input_ids\"][i,1:]\n",
        "      text_tokens = [x.strip(\"ĠĊ\") for x in tokenizer.convert_ids_to_tokens(text_token_ids)]\n",
        "      for j, (index, token) in enumerate(zip(text_token_ids, text_tokens)):\n",
        "          if token != '<|endoftext|>':\n",
        "            #print(probs[i,j,index], j)\n",
        "            s *= probs[i,j,index]\n",
        "      sentence_probability[text] = s\n",
        "      #print(s)\n",
        "      #print(\"\")\n",
        "  markdict = sentence_probability\n",
        "  marklist = sorted(markdict.items(), key=lambda x:x[1], reverse=True)\n",
        "  sortdict = dict(marklist)\n",
        "  a = list(sortdict.keys())\n",
        "  print(a[0], math.log10(sortdict[a[0]]))\n",
        "  if best_three:\n",
        "    if len(a) > 1:\n",
        "      print(a[1], math.log10(sortdict[a[1]]))\n",
        "    if len(a) > 2:\n",
        "      print(a[2], math.log10(sortdict[a[2]]))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcTiGYwhIZXA"
      },
      "source": [
        "let's look on example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-nilRcm0Nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8e9c0a-522e-4078-eced-6619b824b9c5"
      },
      "source": [
        "generate_possible_sentence('He liks intelligen peapel')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He likes intelligent appeal -14.8900343748022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN_IsQ7MVD_B",
        "outputId": "f1bd2773-7003-4a09-d514-78b7e1bfc392"
      },
      "source": [
        "generate_possible_sentence('He likes intelligent peapel. They are really smart')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He likes intelligent appeal They are really smart -24.579315159329713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-bUUIeCVc6-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RPDKty0VddA",
        "outputId": "8a5fad3b-6721-41c2-fc27-176d5ba2400a"
      },
      "source": [
        "generate_possible_sentence('He was very hard person. H makes people angry')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He was very hard person. H makes people angry -27.266935062574156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJAmWf_yVyHK",
        "outputId": "227a1d06-1403-4644-fce1-59f7b79303cd"
      },
      "source": [
        "generate_possible_sentence('He was very hard person. Hi makes people angry')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He was very hard person. Hi makes people angry -29.369194669865823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBtMG8buRHDH"
      },
      "source": [
        "the number means the logarithm of the probability of the given right to offer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0y6Hfk6RULq"
      },
      "source": [
        "let's look on example of best three sentances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU95yFQuIgGN",
        "outputId": "5d8ba683-5fa1-4e71-e139-eeac7c099cfa"
      },
      "source": [
        "generate_possible_sentence('He liks intelligen poeple', best_three = True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He likes intelligent people -10.859718182047587\n",
            "He like intelligent people -12.039852992837014\n",
            "He likes intelligence people -12.702763681423061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO0rPDH0o2bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d26b73-39e7-475b-ac4c-1f7012e1f7dc"
      },
      "source": [
        "generate_possible_sentence('Nice to mete you')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nice to mete you -14.887436033400595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG-hffrcm0Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee18fde-4e9c-46ec-8d4c-6e40ab055924"
      },
      "source": [
        "generate_possible_sentence('Nice to ment you', best_three = True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nice to meet you -6.23056891547142\n",
            "Nice to met you -9.22511285645124\n",
            "Nice to sent you -11.983995502819349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO97-Obzop2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc1ef75-84d7-4e2a-f807-b4b842f53ea6"
      },
      "source": [
        "generate_possible_sentence('Where are you from')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where are you from -5.822051746623529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TQNPJ1Ho6F3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ca9240-f06b-45ad-b7d8-1110b6251008"
      },
      "source": [
        "generate_possible_sentence('Where are you frm', best_three = True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where are you from -5.822049168133126\n",
            "Where are you fro -9.984711659688703\n",
            "Where are you fr -10.156299643015004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OdFh1UapBIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f73e876-b6dc-405d-9bbe-5531e249b1ec"
      },
      "source": [
        "generate_possible_sentence('Wher are you from')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where are you from -5.822059694891647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie-_L86IpG9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c7e246-6a16-4721-e96c-5e670bddc75b"
      },
      "source": [
        "generate_possible_sentence('Where are yu from')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where are you from -5.822052646721279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m5ByahM0TVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc41c190-f9d2-4ab7-db57-74e125d4e407"
      },
      "source": [
        "generate_possible_sentence('Wher is you from')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where is you from -8.00890321694338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsJwgb4Q0oUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c72b23-3ab8-4aa1-ab28-8010b3f17c30"
      },
      "source": [
        "generate_possible_sentence('Wher ar you from')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Where are you from -5.822054530763859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8uAlTRt0x9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8692f6-d727-4710-d10b-8cc2837899c0"
      },
      "source": [
        "generate_possible_sentence('Excuce me, sar, you dropped your wallet')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Excuse me Sara you dropped your wallet -22.20794236369435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFg3CLMS1Qax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dd6569b-ee8c-4b82-fc2e-3b5ef6a31749"
      },
      "source": [
        "generate_possible_sentence('I dod not invit you to the pary.')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I did not invite you to the party -11.473779448857929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRB_WQNi1nwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e0ac84-506c-432a-e2cd-220e843a0e21"
      },
      "source": [
        "generate_possible_sentence('I m really sory')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I m really sorry -10.48651595341332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-9ntdMf1pOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06b11cf-dacd-4000-bc08-0cb2e0c4a7cc"
      },
      "source": [
        "generate_possible_sentence('Im really sory')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm really sorry -5.891609285081461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZOtE2qj1xdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc076de6-0ba0-4294-d04f-e93124338347"
      },
      "source": [
        "generate_possible_sentence('Wht do youthink?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What do outhitting -13.863678994758327\n",
            "Why do outhitting -14.010794880391714\n",
            "Who do outhitting -15.131250615720894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM_OAeu1SUKY"
      },
      "source": [
        "generate_possible_sentence('Oh, never mins')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQjH7_BL2QIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532cd903-d392-41e9-e95d-a22811404c9b"
      },
      "source": [
        "generate_possible_sentence('Oh, never mins')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oh never mind -7.874431643460552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr2sYjrrT0lW"
      },
      "source": [
        "If you have this error it means that there is no enough  memory on colab and you should restart everything:("
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8xutWKB25Ve",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c22e1b3c-cfb5-44dc-8fbb-4f90f42d6b4c"
      },
      "source": [
        "generate_possible_sentence('Im Masha')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-507af4c92473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_possible_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Im Masha'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-9fab68f2398d>\u001b[0m in \u001b[0;36mgenerate_possible_sentence\u001b[0;34m(sentance, best_three)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#  ], dim=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m#print(probs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 190.00 MiB (GPU 0; 14.76 GiB total capacity; 13.43 GiB already allocated; 39.75 MiB free; 13.67 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuGMdI8FTcFl",
        "outputId": "642dcd2e-d770-406d-f673-fa9117713526"
      },
      "source": [
        "generate_possible_sentence('Im Jack')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In Jack -6.849314044971794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsB5mMLGSoog",
        "outputId": "dbc9d886-4f46-427f-b1b6-18b2beccdc44"
      },
      "source": [
        "generate_possible_sentence('Im Jack. I have a son')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm Jack. I have a son -13.190372789967247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXFZj_uSS7Ug",
        "outputId": "846c3623-9fb5-467e-a129-ac04669b8810"
      },
      "source": [
        "generate_possible_sentence('Im Pol. I have a son')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm Pol. I have a son -16.118025857377518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duVCfvdqSzCj",
        "outputId": "04f21959-2140-4eef-de16-1eb23ebac5af"
      },
      "source": [
        "generate_possible_sentence('Im seven years old')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm seven years old -7.590789444221681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNoJoUpdpObw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddb4097-77b0-48e7-9f47-b88658bdb908"
      },
      "source": [
        "generate_possible_sentence('Thaks so muc for the birthdays money.')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thanks so much for the birthdays money. -17.193170857781922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Qf1vh-smM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bc738d-de1a-4b3b-d5f1-89290124a718"
      },
      "source": [
        "generate_possible_sentence('I really appreiate yor help.')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I really appreciate your help. -8.536285601209237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5H0K_nMUXSJ"
      },
      "source": [
        "GPT2 does not know my name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF5cr-Wa0lmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52503c6d-a3dd-42f4-abde-ede2a1457f36"
      },
      "source": [
        "generate_possible_sentence('I am Masha')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am Tasha -8.588813247887964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcZbpydrUV6M",
        "outputId": "fe2230c5-a4b1-4c77-9e74-efed5e03896f"
      },
      "source": [
        "generate_possible_sentence('I am Maria')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am Maria -7.988472099562584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqSQArG-UqTD",
        "outputId": "03d8acd3-9366-43d5-be79-7ce481cb572c"
      },
      "source": [
        "generate_possible_sentence('Input arrays to be multiplid.')\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input arrays to be multiplied -15.16632472214808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmNoRjGsUv9_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fpCTMo4UpWv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eejs_rmUgix"
      },
      "source": [
        ""
      ]
    }
  ]
}